#log loss = -{(y\log(p) + (1 - y)\log(1 - p))}
#the result indicates that being confident and wrong get the largest penalty (largest log loss)
#the labels: correct_confident, actual_labels are all array

def compute_log_loss(predicted, actual, eps=1-14):
  """ Computes the logarithmic loss between predicted and
  actual when these are 1D arrays.
  :param predicted: The predicted probabilities as floats between 0-1
  :param actual: The actual binary labels. Either 0 or 1.
  :param eps (optional): log(0) is inf, so we need to offset our
  predicted values slightly by eps from 0 or 1.
  
  predicted = np.clip(predicted, eps, 1-eps)
  loss = 1- np.mean(actual * np.log(predicted) + (1-actual)*(np.log(1-predicted))
  return loss
  
  # Compute and print log loss for 1st case
correct_confident = compute_log_loss(correct_confident, actual_labels)
print("Log loss, correct and confident: {}".format(correct_confident)) 

# Compute log loss for 2nd case
correct_not_confident = compute_log_loss(correct_not_confident, actual_labels)
print("Log loss, correct and not confident: {}".format(correct_not_confident)) 

# Compute and print log loss for 3rd case
wrong_not_confident = compute_log_loss(wrong_not_confident, actual_labels)
print("Log loss, wrong and not confident: {}".format(wrong_not_confident)) 

# Compute and print log loss for 4th case
wrong_confident = compute_log_loss(wrong_confident, actual_labels)
print("Log loss, wrong and confident: {}".format(wrong_confident)) 

# Compute and print log loss for actual labels
actual_labels = compute_log_loss(actual_labels, actual_labels)
print("Log loss, actual labels: {}".format(actual_labels)) 


